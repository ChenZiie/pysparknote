{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('sales.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|      Country|\n",
      "+-------------+\n",
      "|       Sweden|\n",
      "|       Jersey|\n",
      "|     Malaysia|\n",
      "|       Turkey|\n",
      "|      Germany|\n",
      "|       France|\n",
      "|      Belgium|\n",
      "|      Finland|\n",
      "|United States|\n",
      "|        India|\n",
      "|       Kuwait|\n",
      "|        Malta|\n",
      "|        Italy|\n",
      "|       Norway|\n",
      "|        Spain|\n",
      "|      Denmark|\n",
      "|      Ireland|\n",
      "|       Israel|\n",
      "|      Iceland|\n",
      "|  South Korea|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q1\n",
    "df.select('Country').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   Name|Price|\n",
      "+-------+-----+\n",
      "|Joachim| 1200|\n",
      "|  Diana| 7500|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q2\n",
    "df.filter(\"Country = 'Brazil'\").select('Name','Price').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|      Country|TotalPrice|\n",
      "+-------------+----------+\n",
      "|       Sweden|      8400|\n",
      "|       Jersey|      1200|\n",
      "|     Malaysia|      1200|\n",
      "|       Turkey|      2400|\n",
      "|      Germany|     22800|\n",
      "|       France|     30300|\n",
      "|      Belgium|      3600|\n",
      "|      Finland|      1200|\n",
      "|United States|    350350|\n",
      "|        India|      2400|\n",
      "|       Kuwait|      1200|\n",
      "|        Malta|      3600|\n",
      "|        Italy|      2400|\n",
      "|       Norway|     12000|\n",
      "|        Spain|      2400|\n",
      "|      Denmark|      8400|\n",
      "|      Ireland|     29100|\n",
      "|       Israel|      1200|\n",
      "|      Iceland|      1200|\n",
      "|  South Korea|      1200|\n",
      "+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q3\n",
    "df.groupBy('Country').sum('Price').withColumnRenamed('sum(Price)', 'TotalPrice').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             Country|\n",
      "+--------------------+\n",
      "|       United States|\n",
      "|      United Kingdom|\n",
      "|              Canada|\n",
      "|              France|\n",
      "|             Ireland|\n",
      "|           Australia|\n",
      "|             Germany|\n",
      "|         Switzerland|\n",
      "|         Netherlands|\n",
      "|              Norway|\n",
      "|              Brazil|\n",
      "|              Sweden|\n",
      "|             Denmark|\n",
      "|             Austria|\n",
      "|United Arab Emirates|\n",
      "|        South Africa|\n",
      "|             Belgium|\n",
      "|               Malta|\n",
      "|         New Zealand|\n",
      "|               Italy|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q4\n",
    "df.groupBy('Country').sum('Price').orderBy('sum(Price)', ascending=False).select('Country').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.csv('countries.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| ID|TotalPrice|\n",
      "+---+----------+\n",
      "| 31|      1200|\n",
      "| 34|      2400|\n",
      "| 28|      3600|\n",
      "| 26|      3600|\n",
      "| 27|      1200|\n",
      "| 12|     19200|\n",
      "| 22|      3600|\n",
      "|  1|     63600|\n",
      "| 13|      8400|\n",
      "|  6|     14400|\n",
      "| 16|     12000|\n",
      "|  3|     22800|\n",
      "| 20|      1200|\n",
      "|  5|     30300|\n",
      "| 19|     22800|\n",
      "| 15|      8400|\n",
      "|  9|      2400|\n",
      "| 17|      1200|\n",
      "|  4|      1200|\n",
      "|  8|     42000|\n",
      "+---+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q5\n",
    "df.join(df2, 'Country').groupBy('ID').sum('Price').withColumnRenamed('sum(Price)', 'TotalPrice').show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|src|              rank|\n",
      "+---+------------------+\n",
      "|  1|1.2981882732854677|\n",
      "|  3|0.9999999999999998|\n",
      "|  4|0.9999999999999998|\n",
      "|  2|0.7018117267145316|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q6\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "numOfIterations = 10\n",
    "\n",
    "lines = spark.read.text(\"pagerank_data.txt\")\n",
    "# You can also test your program on the follow larger data set:\n",
    "# lines = spark.read.text(\"dblp.in\")\n",
    "\n",
    "a = lines.select(split(lines[0],' '))\n",
    "links = a.select(a[0][0].alias('src'), a[0][1].alias('dst'))\n",
    "outdegrees = links.groupBy('src').count()\n",
    "ranks = outdegrees.select('src', lit(1).alias('rank'))\n",
    "for iteration in range(numOfIterations):\n",
    "    temp = links.join(ranks,'src').join(outdegrees, 'src')\n",
    "    temp = temp.select(temp['dst'].alias('src'),(temp['rank']/temp['count']).alias('Newrank'))\\\n",
    "            .groupBy('src').sum('Newrank').withColumnRenamed('sum(Newrank)', 'rank')\n",
    "    ranks = temp.select('src',(temp['rank'] * 0.85 + 0.15).alias('rank'))\n",
    "ranks.orderBy(desc('rank')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-54-c81b3c530e19>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-54-c81b3c530e19>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    .groupBy('src').sum('Newrank').withColumnRenamed('sum(Newrank)', 'rank')\u001b[0m\n\u001b[0m                                                                            \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "numOfIterations = 10\n",
    "\n",
    "lines = spark.read.text(\"pagerank_data.txt\")\n",
    "# You can also test your program on the follow larger data set:\n",
    "# lines = spark.read.text(\"dblp.in\")\n",
    "\n",
    "a = lines.select(split(lines[0],' '))\n",
    "links = a.select(a[0][0].alias('src'), a[0][1].alias('dst'))\n",
    "outdegrees = links.groupBy('src').count()\n",
    "ranks = outdegrees.select('src', lit(1).alias('rank'))\n",
    "for iteration in range(numOfIterations):\n",
    "    temp = links.join(ranks,'src').join(outdegrees, 'src')\n",
    "    temp = temp.select(temp['dst'].alias('src'),(temp['rank']/temp['count']).alias('Newrank'))\\\n",
    "            .groupBy('src').sum('Newrank').withColumnRenamed('sum(Newrank)', 'rank')\n",
    "    ranks = temp.select('src',(temp['rank'] * 0.85 + 0.15).alias('rank'))\n",
    "ranks.orderBy(desc('rank')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
